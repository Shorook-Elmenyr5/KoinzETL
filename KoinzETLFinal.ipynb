{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "##Install Java + Spark\n",
        "!apt-get install -y openjdk-11-jdk\n",
        "!wget https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar -xzf spark-3.5.0-bin-hadoop3.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCDNa1FigQBI",
        "outputId": "82726e40-e884-42d5-8599-2a3befac7830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libxcomposite1 libxt-dev libxtst6 libxxf86dga1\n",
            "  openjdk-11-jdk-headless openjdk-11-jre openjdk-11-jre-headless\n",
            "  session-migration x11-utils\n",
            "Suggested packages:\n",
            "  libxt-doc openjdk-11-demo openjdk-11-source visualvm libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  | fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libxcomposite1 libxt-dev libxtst6 libxxf86dga1\n",
            "  openjdk-11-jdk openjdk-11-jdk-headless openjdk-11-jre\n",
            "  openjdk-11-jre-headless session-migration x11-utils\n",
            "0 upgraded, 20 newly installed, 0 to remove and 1 not upgraded.\n",
            "Need to get 124 MB of archives.\n",
            "After this operation, 277 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 at-spi2-core amd64 2.44.0-3 [54.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre-headless amd64 11.0.29+7-1ubuntu1~22.04 [42.6 MB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.29+7-1ubuntu1~22.04 [214 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk-headless amd64 11.0.29+7-1ubuntu1~22.04 [73.6 MB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk amd64 11.0.29+7-1ubuntu1~22.04 [2,984 kB]\n",
            "Fetched 124 MB in 4s (30.7 MB/s)\n",
            "Selecting previously unselected package libatspi2.0-0:amd64.\n",
            "(Reading database ... 117528 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libatspi2.0-0_2.44.0-3_amd64.deb ...\n",
            "Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../01-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../02-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../03-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package at-spi2-core.\n",
            "Preparing to unpack .../04-at-spi2-core_2.44.0-3_amd64.deb ...\n",
            "Unpacking at-spi2-core (2.44.0-3) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../05-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../06-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libatk1.0-data.\n",
            "Preparing to unpack .../07-libatk1.0-data_2.36.0-3build1_all.deb ...\n",
            "Unpacking libatk1.0-data (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk1.0-0:amd64.\n",
            "Preparing to unpack .../08-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n",
            "Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
            "Preparing to unpack .../09-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n",
            "Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Selecting previously unselected package libxcomposite1:amd64.\n",
            "Preparing to unpack .../10-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n",
            "Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../11-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../12-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../13-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../14-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../15-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-11-jre-headless:amd64.\n",
            "Preparing to unpack .../16-openjdk-11-jre-headless_11.0.29+7-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-11-jre-headless:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-11-jre:amd64.\n",
            "Preparing to unpack .../17-openjdk-11-jre_11.0.29+7-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-11-jre:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-11-jdk-headless:amd64.\n",
            "Preparing to unpack .../18-openjdk-11-jdk-headless_11.0.29+7-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-11-jdk-headless:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-11-jdk:amd64.\n",
            "Preparing to unpack .../19-openjdk-11-jdk_11.0.29+7-1ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-11-jdk:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-11-jre-headless:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up openjdk-11-jre:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
            "Setting up openjdk-11-jdk-headless:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jaotc to provide /usr/bin/jaotc (jaotc) in auto mode\n",
            "Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up libatk1.0-data (2.36.0-3build1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up openjdk-11-jdk:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Setting up at-spi2-core (2.44.0-3) ...\n",
            "--2026-01-11 18:52:25--  https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400395283 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.0-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.0-bin-had 100%[===================>] 381.85M  24.0MB/s    in 17s     \n",
            "\n",
            "2026-01-11 18:52:43 (22.0 MB/s) - ‘spark-3.5.0-bin-hadoop3.tgz’ saved [400395283/400395283]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMypsttyObV7",
        "outputId": "42eac7b3-15ee-4fc0-aa15-d443dde76789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting clickhouse-connect\n",
            "  Downloading clickhouse_connect-0.10.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting supabase\n",
            "  Downloading supabase-2.27.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from clickhouse-connect) (2025.11.12)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.12/dist-packages (from clickhouse-connect) (2.5.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from clickhouse-connect) (2025.2)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.12/dist-packages (from clickhouse-connect) (0.25.0)\n",
            "Collecting lz4 (from clickhouse-connect)\n",
            "  Downloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting realtime==2.27.1 (from supabase)\n",
            "  Downloading realtime-2.27.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting supabase-functions==2.27.1 (from supabase)\n",
            "  Downloading supabase_functions-2.27.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting storage3==2.27.1 (from supabase)\n",
            "  Downloading storage3-2.27.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting supabase-auth==2.27.1 (from supabase)\n",
            "  Downloading supabase_auth-2.27.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting postgrest==2.27.1 (from supabase)\n",
            "  Downloading postgrest-2.27.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: httpx<0.29,>=0.26 in /usr/local/lib/python3.12/dist-packages (from supabase) (0.28.1)\n",
            "Requirement already satisfied: yarl>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from supabase) (1.22.0)\n",
            "Requirement already satisfied: deprecation>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from postgrest==2.27.1->supabase) (2.1.0)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.9 in /usr/local/lib/python3.12/dist-packages (from postgrest==2.27.1->supabase) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from realtime==2.27.1->supabase) (4.15.0)\n",
            "Requirement already satisfied: websockets<16,>=11 in /usr/local/lib/python3.12/dist-packages (from realtime==2.27.1->supabase) (15.0.1)\n",
            "Collecting pyiceberg>=0.10.0 (from storage3==2.27.1->supabase)\n",
            "  Downloading pyiceberg-0.10.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->supabase-auth==2.27.1->supabase) (2.10.1)\n",
            "Collecting strenum>=0.4.15 (from supabase-functions==2.27.1->supabase)\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.26->supabase) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.26->supabase) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.26->supabase) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.12/dist-packages (from yarl>=1.22.0->supabase) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from yarl>=1.22.0->supabase) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from deprecation>=2.1.0->postgrest==2.27.1->supabase) (25.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]<0.29,>=0.26->postgrest==2.27.1->supabase) (4.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.9->postgrest==2.27.1->supabase) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.9->postgrest==2.27.1->supabase) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0,>=1.9->postgrest==2.27.1->supabase) (0.4.2)\n",
            "Requirement already satisfied: cachetools<7.0,>=5.5 in /usr/local/lib/python3.12/dist-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (6.2.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.12/dist-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (8.3.1)\n",
            "Requirement already satisfied: fsspec>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (2025.3.0)\n",
            "Requirement already satisfied: mmh3<6.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (5.2.0)\n",
            "Requirement already satisfied: pyparsing<4.0.0,>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (3.2.5)\n",
            "Collecting pyroaring<2.0.0,>=1.0.0 (from pyiceberg>=0.10.0->storage3==2.27.1->supabase)\n",
            "  Downloading pyroaring-1.0.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (2.32.4)\n",
            "Requirement already satisfied: rich<15.0.0,>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (13.9.4)\n",
            "Collecting sortedcontainers==2.4.0 (from pyiceberg>=0.10.0->storage3==2.27.1->supabase)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting strictyaml<2.0.0,>=1.7.0 (from pyiceberg>=0.10.0->storage3==2.27.1->supabase)\n",
            "  Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: tenacity<10.0.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from pyiceberg>=0.10.0->storage3==2.27.1->supabase) (9.1.2)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->supabase-auth==2.27.1->supabase) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->supabase-auth==2.27.1->supabase) (2.0.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->postgrest==2.27.1->supabase) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->postgrest==2.27.1->supabase) (4.1.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.20.0->pyiceberg>=0.10.0->storage3==2.27.1->supabase) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=10.11.0->pyiceberg>=0.10.0->storage3==2.27.1->supabase) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=10.11.0->pyiceberg>=0.10.0->storage3==2.27.1->supabase) (2.19.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->supabase-auth==2.27.1->supabase) (2.23)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=10.11.0->pyiceberg>=0.10.0->storage3==2.27.1->supabase) (0.1.2)\n",
            "Downloading clickhouse_connect-0.10.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading supabase-2.27.1-py3-none-any.whl (16 kB)\n",
            "Downloading postgrest-2.27.1-py3-none-any.whl (21 kB)\n",
            "Downloading realtime-2.27.1-py3-none-any.whl (22 kB)\n",
            "Downloading storage3-2.27.1-py3-none-any.whl (27 kB)\n",
            "Downloading supabase_auth-2.27.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading supabase_functions-2.27.1-py3-none-any.whl (8.5 kB)\n",
            "Downloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyiceberg-0.10.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
            "Downloading pyroaring-1.0.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: strenum, sortedcontainers, pyroaring, lz4, strictyaml, clickhouse-connect, realtime, pyiceberg, supabase-functions, supabase-auth, storage3, postgrest, supabase\n",
            "Successfully installed clickhouse-connect-0.10.0 lz4-4.4.5 postgrest-2.27.1 pyiceberg-0.10.0 pyroaring-1.0.3 realtime-2.27.1 sortedcontainers-2.4.0 storage3-2.27.1 strenum-0.4.15 strictyaml-1.7.3 supabase-2.27.1 supabase-auth-2.27.1 supabase-functions-2.27.1\n"
          ]
        }
      ],
      "source": [
        "#Install Dependencies\n",
        "!pip install clickhouse-connect supabase pyspark pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clickhouse-connect\n",
        "!pip install psycopg2-binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4aH-AKQZp_B",
        "outputId": "3d23e83f-408d-4c8e-9e99-24924e1431e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: clickhouse-connect in /usr/local/lib/python3.12/dist-packages (0.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from clickhouse-connect) (2025.11.12)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.12/dist-packages (from clickhouse-connect) (2.5.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from clickhouse-connect) (2025.2)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.12/dist-packages (from clickhouse-connect) (0.25.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.12/dist-packages (from clickhouse-connect) (4.4.5)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.11-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\n",
            "Downloading psycopg2_binary-2.9.11-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
            "Successfully installed psycopg2-binary-2.9.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!java -version\n",
        "#to see the version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp3IoQAZZ7Pm",
        "outputId": "124d761f-6e57-49a6-8ab0-6ba9fca85f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"17.0.17\" 2025-10-21\n",
            "OpenJDK Runtime Environment (build 17.0.17+10-Ubuntu-122.04)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.17+10-Ubuntu-122.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from supabase import create_client\n",
        "import clickhouse_connect\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "PSPnL66lahOO"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up Spark Session\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Koinz_ETL\") \\\n",
        "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.6.0\") \\\n",
        "    .getOrCreate()\n"
      ],
      "metadata": {
        "id": "QNAd2XM5aBO7"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ClickHouse Client"
      ],
      "metadata": {
        "id": "bdaqnZS3bgRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup ClickHouse Client\n",
        "import clickhouse_connect\n",
        "\n",
        "ch_client = clickhouse_connect.get_client(\n",
        "    host='cbz3zgbmhe.europe-west4.gcp.clickhouse.cloud',\n",
        "    user='default',\n",
        "    password='ojSGSKQMB8xI.',\n",
        "    secure=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "E5Z8Eb2xTAX8"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fot testing the connection\n",
        "print(\"Test ClickHouse:\", ch_client.query(\"SELECT 1\").result_set[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daobRK_RaUgm",
        "outputId": "2f9e9cd6-a285-4b9a-e3f2-730e8925cb5b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test ClickHouse: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using updated_at ensures updated rows are captured.\n",
        "\n",
        "First run → full load from epoch."
      ],
      "metadata": {
        "id": "rAcnJE-3ggq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Checkpoint Table\n",
        "def get_last_checkpoint(job_name: str):\n",
        "    result = ch_client.query(f\"\"\"\n",
        "        SELECT max(last_processed_timestamp)\n",
        "        FROM etl_checkpoint\n",
        "        WHERE job_name = '{job_name}'\n",
        "    \"\"\").result_set\n",
        "\n",
        "    if not result or result[0][0] is None:\n",
        "        # First run → full load\n",
        "        return \"1970-01-01 00:00:00.000\"\n",
        "\n",
        "    return result[0][0]"
      ],
      "metadata": {
        "id": "oyHyWY1ga9WJ"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##test\n",
        "last_ts = get_last_checkpoint(\"app_user_visits_fact\")\n",
        "print(\"Last processed timestamp:\", last_ts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv6BIb1cbPLL",
        "outputId": "1a7a8545-fef0-412f-8fd3-84fba8c2eae1"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last processed timestamp: 2025-10-01 18:00:46.839000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Data from Postgres"
      ],
      "metadata": {
        "id": "vXJKu_x2balm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "import datetime\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-d0FZ1qPg6UY"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SetUp supabase for postgres DB\n",
        "pg_url = \"jdbc:postgresql://aws-1-eu-west-1.pooler.supabase.com:5432/postgres\"\n",
        "pg_properties = {\n",
        "    \"user\": \"postgres.ioluevezsodwdfpxpnce\",\n",
        "    \"password\": \"ONWuOe4nTsKln0ur\",\n",
        "    \"driver\": \"org.postgresql.Driver\",\n",
        "    \"sslmode\": \"require\"\n",
        "}"
      ],
      "metadata": {
        "id": "dJqG398ng2-S"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "\n",
        "#Add optional 5-min overlap to catch delayed updates\n",
        "last_ts_dt = pd.to_datetime(last_ts)\n",
        "overlap_ts_dt = (last_ts_dt - timedelta(minutes=5))\n",
        "\n",
        "# Convert datetime object to epoch milliseconds for comparison with BIGINT column\n",
        "overlap_ts_epoch_ms = int(overlap_ts_dt.timestamp() * 1000)\n",
        "\n",
        "query = f\"\"\"\n",
        "(\n",
        "  SELECT *\n",
        "  FROM app_user_visits_fact\n",
        "  WHERE updated_at >= {overlap_ts_epoch_ms}\n",
        ") AS recent_visits\n",
        "\"\"\"\n",
        "\n",
        "df_postgres = spark.read.jdbc(\n",
        "    url=pg_url,\n",
        "    table=query,\n",
        "    properties=pg_properties\n",
        ")\n",
        "\n",
        "print(\"Rows fetched from Postgres:\", df_postgres.count())\n",
        "df_postgres.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQmEwk7ygm2Z",
        "outputId": "a9cd5149-9d5f-46d6-f392-404efa904822"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows fetched from Postgres: 4\n",
            "+------------------------------------+------------+----+-----+------+-------+-----------+---------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+-------------+-------------+-------+----------+------------------------------------+----------+--------+---------------+--------------+\n",
            "|id                                  |phone_number|seen|state|points|receipt|countryCode|remaining|customer_id                         |branch_id                           |store_id                            |cashier_id                          |created_at   |updated_at   |expired|expires_at|order_id                            |is_deleted|is_fraud|sync_mechanism |is_bulk_points|\n",
            "+------------------------------------+------------+----+-----+------+-------+-----------+---------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+-------------+-------------+-------+----------+------------------------------------+----------+--------+---------------+--------------+\n",
            "|92128927-eaf7-4e31-9269-7f8c38e4d1cc|0550693380  |1   |2    |11.0  |11.64  |+966       |0.0      |935a56d5-6ba5-4afa-a021-5f68ca979d95|b9e6030c-e493-44a7-b703-a43d7bc581b0|cc379a3a-3587-4c90-90d2-fecaf0c17280|bdef37c4-be15-4599-970f-c8cf953c74bd|1758628843010|1759341646369|NULL   |NULL      |bcd80a6f-b99b-4b91-85fb-7fd460f216c8|0         |0       |messaging_queue|              |\n",
            "|0b4b4a83-2c37-4fae-8f10-9cdcf4403e70|0550693380  |1   |2    |9.0   |9.54   |+966       |0.0      |935a56d5-6ba5-4afa-a021-5f68ca979d95|abb72289-ab34-4920-a306-387cda5aa3de|cc379a3a-3587-4c90-90d2-fecaf0c17280|1e6098ca-1167-4973-aca2-4cc99558fa0d|1758736479787|1759341646479|NULL   |NULL      |27a4b82a-ae78-4c9d-a261-cddc85885576|0         |0       |messaging_queue|              |\n",
            "|5bfb3f5d-4160-49e2-9e20-0d4b64786537|0550693380  |1   |2    |11.0  |11.93  |+966       |0.0      |935a56d5-6ba5-4afa-a021-5f68ca979d95|abb72289-ab34-4920-a306-387cda5aa3de|cc379a3a-3587-4c90-90d2-fecaf0c17280|1e6098ca-1167-4973-aca2-4cc99558fa0d|1758914040646|1759341646653|NULL   |NULL      |154241ee-b942-4ce0-b7bc-a1e3d3316ec8|0         |0       |messaging_queue|              |\n",
            "|89ea0a7a-52ef-4290-b681-c4463db4d35c|0550693380  |1   |2    |7.0   |7.46   |+966       |2.0      |935a56d5-6ba5-4afa-a021-5f68ca979d95|abb72289-ab34-4920-a306-387cda5aa3de|cc379a3a-3587-4c90-90d2-fecaf0c17280|1e6098ca-1167-4973-aca2-4cc99558fa0d|1759173190174|1759341646839|NULL   |NULL      |4d620ec1-23ac-4f28-87d1-72fa9df8d3f8|0         |0       |messaging_queue|              |\n",
            "+------------------------------------+------------+----+-----+------+-------+-----------+---------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+-------------+-------------+-------+----------+------------------------------------+----------+--------+---------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformation & Insert into ClickHouse"
      ],
      "metadata": {
        "id": "QRCrK8mxdiez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Transform timestamps& Rename -->Matches DateTime64(3)& Preserves millisecond precision &Safe for nulls\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "df_transformed = (\n",
        "    df_postgres\n",
        "    # Rename countryCode → country_code\n",
        "    .withColumnRenamed(\"countryCode\", \"country_code\")\n",
        "\n",
        "    # created_at\n",
        "    .withColumn(\n",
        "        \"created_at\",\n",
        "        (F.col(\"created_at\") / 1000).cast(\"timestamp\")\n",
        "    )\n",
        "    # updated_at\n",
        "    .withColumn(\n",
        "        \"updated_at\",\n",
        "        (F.col(\"updated_at\") / 1000).cast(\"timestamp\")\n",
        "    )\n",
        "    # expires_at (nullable)\n",
        "    .withColumn(\n",
        "        \"expires_at\",\n",
        "        F.when(\n",
        "            F.col(\"expires_at\").isNotNull(),\n",
        "            (F.col(\"expires_at\") / 1000).cast(\"timestamp\")\n",
        "        )\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "f9v7nBEHcxIs"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Enforce ClickHouse data types\n",
        "#1)Flags → UInt8\n",
        "flag_cols = [\"seen\", \"expired\", \"is_deleted\", \"is_fraud\"]\n",
        "\n",
        "for c in flag_cols:\n",
        "    df_transformed = df_transformed.withColumn(\n",
        "        c,\n",
        "        F.col(c).cast(\"int\")\n",
        "    )\n"
      ],
      "metadata": {
        "id": "tSelDDYpjCpH"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Enforce ClickHouse data types\n",
        "#2)Decimal columns\n",
        "decimal_cols = [\"points\", \"receipt\", \"remaining\"]\n",
        "\n",
        "for c in decimal_cols:\n",
        "    df_transformed = df_transformed.withColumn(\n",
        "        c,\n",
        "        F.col(c).cast(\"decimal(10,2)\")\n",
        "    )\n"
      ],
      "metadata": {
        "id": "3muJRLXmjw4m"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLUMN_MAPPING = {\n",
        "    \"countryCode\": \"country_code\",\n",
        "    \"createdAt\": \"created_at\",\n",
        "    \"updatedAt\": \"updated_at\",\n",
        "    \"expiresAt\": \"expires_at\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "hzzVZ_TapMWW"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for src, tgt in COLUMN_MAPPING.items():\n",
        "    if src in df_postgres.columns:\n",
        "        df_transformed = df_transformed.withColumnRenamed(src, tgt)\n"
      ],
      "metadata": {
        "id": "CRNaEoyBpPI-"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Column selection & order\n",
        "final_cols = [\n",
        "    \"id\",\n",
        "    \"phone_number\",\n",
        "    \"customer_id\",\n",
        "    \"seen\",\n",
        "    \"state\",\n",
        "    \"expired\",\n",
        "    \"is_deleted\",\n",
        "    \"is_fraud\",\n",
        "    \"points\",\n",
        "    \"receipt\",\n",
        "    \"remaining\",\n",
        "    \"country_code\",\n",
        "    \"branch_id\",\n",
        "    \"store_id\",\n",
        "    \"cashier_id\",\n",
        "    \"order_id\",\n",
        "    \"created_at\",\n",
        "    \"updated_at\",\n",
        "    \"expires_at\",\n",
        "    \"sync_mechanism\",\n",
        "    \"is_bulk_points\"\n",
        "]\n",
        "\n",
        "df_final = df_transformed.select(*final_cols)\n",
        "##A Nte we do NOT include _ingested_at ClickHouse fills it automatically"
      ],
      "metadata": {
        "id": "gSjgAvYEpywt"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.show(10, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv75RJT8s_uT",
        "outputId": "103461cd-73c6-4f63-ecb4-b6d7beac04b2"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------+------------+------------------------------------+----+-----+-------+----------+--------+------+-------+---------+------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+-----------------------+-----------------------+----------+---------------+--------------+\n",
            "|id                                  |phone_number|customer_id                         |seen|state|expired|is_deleted|is_fraud|points|receipt|remaining|country_code|branch_id                           |store_id                            |cashier_id                          |order_id                            |created_at             |updated_at             |expires_at|sync_mechanism |is_bulk_points|\n",
            "+------------------------------------+------------+------------------------------------+----+-----+-------+----------+--------+------+-------+---------+------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+-----------------------+-----------------------+----------+---------------+--------------+\n",
            "|92128927-eaf7-4e31-9269-7f8c38e4d1cc|0550693380  |935a56d5-6ba5-4afa-a021-5f68ca979d95|1   |2    |NULL   |0         |0       |11.00 |11.64  |0.00     |+966        |b9e6030c-e493-44a7-b703-a43d7bc581b0|cc379a3a-3587-4c90-90d2-fecaf0c17280|bdef37c4-be15-4599-970f-c8cf953c74bd|bcd80a6f-b99b-4b91-85fb-7fd460f216c8|2025-09-23 12:00:43.01 |2025-10-01 18:00:46.369|NULL      |messaging_queue|              |\n",
            "|0b4b4a83-2c37-4fae-8f10-9cdcf4403e70|0550693380  |935a56d5-6ba5-4afa-a021-5f68ca979d95|1   |2    |NULL   |0         |0       |9.00  |9.54   |0.00     |+966        |abb72289-ab34-4920-a306-387cda5aa3de|cc379a3a-3587-4c90-90d2-fecaf0c17280|1e6098ca-1167-4973-aca2-4cc99558fa0d|27a4b82a-ae78-4c9d-a261-cddc85885576|2025-09-24 17:54:39.787|2025-10-01 18:00:46.479|NULL      |messaging_queue|              |\n",
            "|5bfb3f5d-4160-49e2-9e20-0d4b64786537|0550693380  |935a56d5-6ba5-4afa-a021-5f68ca979d95|1   |2    |NULL   |0         |0       |11.00 |11.93  |0.00     |+966        |abb72289-ab34-4920-a306-387cda5aa3de|cc379a3a-3587-4c90-90d2-fecaf0c17280|1e6098ca-1167-4973-aca2-4cc99558fa0d|154241ee-b942-4ce0-b7bc-a1e3d3316ec8|2025-09-26 19:14:00.646|2025-10-01 18:00:46.653|NULL      |messaging_queue|              |\n",
            "|89ea0a7a-52ef-4290-b681-c4463db4d35c|0550693380  |935a56d5-6ba5-4afa-a021-5f68ca979d95|1   |2    |NULL   |0         |0       |7.00  |7.46   |2.00     |+966        |abb72289-ab34-4920-a306-387cda5aa3de|cc379a3a-3587-4c90-90d2-fecaf0c17280|1e6098ca-1167-4973-aca2-4cc99558fa0d|4d620ec1-23ac-4f28-87d1-72fa9df8d3f8|2025-09-29 19:13:10.174|2025-10-01 18:00:46.839|NULL      |messaging_queue|              |\n",
            "+------------------------------------+------------+------------------------------------+----+-----+-------+----------+--------+------+-------+---------+------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+-----------------------+-----------------------+----------+---------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expected_cols = set(final_cols)\n",
        "actual_cols = set(df_final.columns)\n",
        "\n",
        "missing = expected_cols - actual_cols\n",
        "extra = actual_cols - expected_cols\n",
        "\n",
        "if missing:\n",
        "    raise Exception(f\"Missing columns before ClickHouse load: {missing}\")\n",
        "\n",
        "if extra:\n",
        "    print(f\"Warning: extra columns ignored: {extra}\")\n"
      ],
      "metadata": {
        "id": "0xzjlCi_pSn2"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLICKHOUSE_COLUMNS = [\n",
        "    \"id\",\n",
        "    \"phone_number\",\n",
        "    \"customer_id\",\n",
        "    \"seen\",\n",
        "    \"state\",\n",
        "    \"expired\",\n",
        "    \"is_deleted\",\n",
        "    \"is_fraud\",\n",
        "    \"points\",\n",
        "    \"receipt\",\n",
        "    \"remaining\",\n",
        "    \"country_code\",\n",
        "    \"branch_id\",\n",
        "    \"store_id\",\n",
        "    \"cashier_id\",\n",
        "    \"order_id\",\n",
        "    \"created_at\",\n",
        "    \"updated_at\",\n",
        "    \"expires_at\",\n",
        "    \"sync_mechanism\",\n",
        "    \"is_bulk_points\"\n",
        "]\n",
        "\n",
        "DATETIME_COLS = [\"created_at\", \"updated_at\", \"expires_at\"]\n",
        "UINT8_COLS = [\"seen\", \"expired\", \"is_deleted\", \"is_fraud\"]\n",
        "\n",
        "\n",
        "def clean_datetime(series):\n",
        "    def _convert(x):\n",
        "        if pd.isna(x):\n",
        "            return None\n",
        "        if isinstance(x, pd.Timestamp):\n",
        "            return x.to_pydatetime()\n",
        "        if isinstance(x, datetime.datetime):\n",
        "            return x\n",
        "        return None\n",
        "    return series.apply(_convert)\n",
        "\n",
        "\n",
        "def normalize_uint8(series, default=0):\n",
        "    def _convert(x):\n",
        "        if x is None or pd.isna(x):\n",
        "            return default\n",
        "        return int(bool(x))\n",
        "    return series.apply(_convert)\n",
        "\n",
        "\n",
        "def insert_to_clickhouse(df_spark, job_name=\"app_user_visits_fact\"):\n",
        "    if df_spark.rdd.isEmpty():\n",
        "        print(\"No new data to insert.\")\n",
        "        return\n",
        "\n",
        "    # Convert to Pandas\n",
        "    df = df_spark.toPandas()\n",
        "\n",
        "    # Ensure required columns exist\n",
        "    missing_cols = set(CLICKHOUSE_COLUMNS) - set(df.columns)\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "    # Clean datetime columns\n",
        "    for col in DATETIME_COLS:\n",
        "        df[col] = clean_datetime(df[col])\n",
        "\n",
        "    # Normalize UInt8 flags\n",
        "    for col in UINT8_COLS:\n",
        "        df[col] = normalize_uint8(df[col])\n",
        "\n",
        "    # Replace NaN → None\n",
        "    df = df.replace({np.nan: None})\n",
        "\n",
        "    # Insert into fact table\n",
        "    ch_client.insert(\n",
        "        table=\"app_user_visits_fact\",\n",
        "        column_names=CLICKHOUSE_COLUMNS,\n",
        "        data=df[CLICKHOUSE_COLUMNS].values.tolist()\n",
        "    )\n",
        "\n",
        "    # Compute checkpoint safely\n",
        "    updated_ts_series = df[\"updated_at\"].dropna()\n",
        "    if updated_ts_series.empty:\n",
        "        raise ValueError(\"All updated_at values are NULL. Cannot update checkpoint.\")\n",
        "\n",
        "    max_ts = updated_ts_series.max()\n",
        "\n",
        "    # Insert checkpoint\n",
        "    ch_client.insert(\n",
        "        table=\"etl_checkpoint\",\n",
        "        column_names=[\n",
        "            \"job_name\",\n",
        "            \"last_processed_timestamp\",\n",
        "            \"rows_processed\",\n",
        "            \"status\",\n",
        "            \"error_message\",\n",
        "            \"updated_at\"\n",
        "        ],\n",
        "        data=[[\n",
        "            job_name,\n",
        "            max_ts,\n",
        "            int(len(df)),\n",
        "            \"success\",\n",
        "            None,\n",
        "            datetime.datetime.now()\n",
        "        ]]\n",
        "    )\n",
        "\n",
        "    print(f\"Inserted {len(df)} rows. Checkpoint updated to {max_ts}\")\n"
      ],
      "metadata": {
        "id": "qPV_tQwMsLfk"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insert_to_clickhouse(df_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vlEr_c7ySnw",
        "outputId": "1e80f890-79fc-48b6-b40b-623568f2d6f9"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 4 rows. Checkpoint updated to 2025-10-01 18:00:46.839000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zNgRRjpmyWS1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}